# 迁移学习常用算法及数据资源

为了研究及测试算法性能，收集了若干来自图像、文本、及时间序列的公开数据集。并且，为了与自己所研究的算法进行对比，收集了领域内若干较前沿的算法及其相关代码，以便后期进行算法的比较测试。

## 数据集

下表收集了迁移学习领域常用的数据集。这些数据集的详细介绍和下载地址，在[Github](https://github.com/jindongwang/transferlearning/blob/master/doc/dataset.md)上可以找到。我们还在[Benchmark](https://github.com/jindongwang/transferlearning/blob/master/doc/benchmark.md)上提供了一些常用算法的实验结果。

| 序号 | 数据集 | 类型 | 样本数 | 特征数 | 类别数 |
|:-------------:|:---------------:|:-------------:|:---------------:|:---------------:|:---------------:|
|       1       |       USPS      |    字符识别   |       1800      |       256       |        10       |
|       2       |      MNIST      |    字符识别   |       2000      |       256       |        10       |
|       3       |       PIE       |    人脸识别   |      11554      |       1024      |        68       |
|       4       |      COIL20     |    对象识别   |       1440      |       1024      |        20       |
|       5       |  Office+Caltech |    对象识别   |       2533      |       800       |        10       |
|       6       |     ImageNet    |    图像分类   |       7341      |       4096      |        5        |
|       7       |     VOC2007     |    图像分类   |       3376      |       4096      |        5        |
|       8       |     LabelMe     |    图像分类   |       2656      |       4096      |        5        |
|       9       |      SUN09      |    图像分类   |       3282      |       4096      |        5        |
|       10      |    Caltech101   |    图像分类   |       1415      |       4096      |        5        |
|       11      |   20newsgroup   |    文本分类   |      25804      |        /        |        6        |
|       12      |  Reuters-21578  |    文本分类   |       4771      |        /        |        3        |
|       13      |   OPPORTUNITY   |    行为识别   |      701366     |        27       |        4        |
|       14      |      DSADS      |    行为识别   |     2844868     |        27       |        19       |
|       15      |      PAMAP2     |    行为识别   |     1140000     |        27       |        18       |


## 手写体识别图像数据集

MNIST和USPS是两个通用的手写体识别数据集，它们被广泛地应用于机器学习算法评测的各个方面。USPS数据集包括7,291张训练图片和2,007张测试图片，图片大小为16$$\times$$16。MNIST数据集包括60,000张训练图片和10,000张测试图片，图片大小28$$\times$$28。USPS和MNIST数据集分别服从显著不同的概率分布，两个数据集都包含10个类别，每个类别是1-10之间的某个字符。为了构造迁移学习人物，在USPS中随机选取1,800张图片作为辅助数据、在MNIST中随机选取2,000张图片作为目标数据。交换辅助领域和目标领域可以得到另一个分类任务MNIST vs USPS。图片预处理包括:将所有图片大小线性缩放为16$$\times$$16，每幅图片用256维的特征向量表征，编码了图片的像素灰度值信息。辅助领域和目标领域共享特征空间和类别空间，但数据分布显著不同。

## 人脸识别图像数据集

PIE代表“朝向、光照、表情”的英文单词首字母，该数据集是人脸识别的基准测试集，包括68个不同人物的41,368幅人脸照片，图片大小为32$$\times$$32，每个人物的照片由13个同步的相机(不同朝向)、21个不同曝光程度拍摄。简单起见，实验中采用PIE的预处理集，包括2个不同子集PIE1和PIE2，是从正面朝向的人脸照片集合(C27)中按照不同的光照和曝光条件随机选出。按如下方法构造分类任务PIEI vs PIE2：将PIE1作为辅助领域、PIE2作为目标领域;交换辅助领域和目标领域可以得到分类任务PIE2 vs PIEI。这样，辅助领域和目标领域分别由不同光照、曝光条件的人脸照片组成，从而服从显著不同的概率分布。

## 对象识别数据集

COIL20包含20个对象类别共1,440张图片;每个对象类别包括72张图片，每张图片拍摄时对象水平旋转5度(共360度)。每幅图片大小为32$$\times$$32，表征为1,024维的向量。实验中将该数据集划分为两个不相交的子集COIL1和COIL2：COIL1包括位于拍摄角度为$$[0\textdegree,85\textdegree]\cup[180\textdegree,265\textdegree]$$(第一、三象限)的所有图片；COIL2包括位于拍摄角度为$$[90\textdegree,175\textdegree]\cup[270\textdegree,355\textdegree]$$(第二、四象限)的所有图片。这样，子集COIL1和COIL2的图片因为拍摄角度不同而服从不同的概率分布。将COIL1作为辅助领域、COIL2作为目标领域，可以构造跨领域分类任务COIL1 vs COIL2；交换辅助领域和目标领域，可以得到另外一个分类任务COIL2 vs COIL1。

Office是视觉迁移学习的主流基准数据集，包含3个对象领域Amazon(在线电商图片)、Webcam(网络摄像头拍摄的低解析度图片)、DSLR(单反相机拍摄的高解析度图片)，共有4,652张图片31个类别标签。Caltech-256是对象识别的基准数据集，包括1个对象领域Caltech，共有30,607张图片256个类别标签。对每张图片抽取SURF特征，并向量化为800维的直方图表征，所有直方图向量都进行减均值除方差的归一化处理，直方图码表由K均值聚类算法在Amazon子集上生成。具体共有4个领域C(Caltech-256), A(Amazon), W(Webcam)和D(DSLR)，从中随机选取2个不同的领域作为辅助领域和目标领域，则可构造$$4 \times 3 = 12$$个跨领域视觉对象识别任务，如$$A \rightarrow D, A \rightarrow C, \cdots, C \rightarrow W$$。

## 大规模图像分类数据集

大规模图像分类数据集包含了来自5个域的图像数据：ImageNet、VOC 2007、SUN、LabelMe、以及Caltech。它们包含5个类别的图像数据：鸟，猫，椅子，狗，人。对于每个域的数据，均使用DeCaf~\cite{donahue2014decaf}进行特征提取，并取第6层的特征作为实验使用，简称DeCaf6特征。每个样本有4096个维度。

## 通用文本分类数据集

20-Newsgroups数据集包含约20,000个文档，4个大类分别为comp, rec,sci和talk，每个大类包含4个子类，详细信息如表2.2所示。在实验中构造了6组跨领域二分类任务，每组任务由4个大类中随机选取2个大类构成，一个大类记为正例，另一个大类记为负例，6个任务组具体为comp vs rec, comp vs sci, comp vs talk,  rec vs sci,  rec vs talk和、sci vs talk。每个跨领域分类任务(包括辅助领域和目标领域)按如下方法生成:每个任务组p VS的两个大类p和Q分别包含4个子类P1、P2、P3、P4和Q1、Q2、Q3、Q4;随机选取p的两个子类(如P1、P2)与Q的两个子类(如Q1、Q2)构成辅助领域，其余子类(P的P3和P4和Q3和Q4构成目标领域。以上构造策略既保证辅助领域和目标领域是相关的，因为它们都来自同样的大类;又保证辅助领域和目标领域是不同的，因为它们来自不同的子类。每个任务组P VS Q可以生成36个分类任务，总计6个任务组共生成6$$\times$$36 = 216个分类任务。数据集经过文本预处理后包含25,804个词项特征和15,033个文档，每个文档由tf-idf向量表征。

Reuters-21578是一个较难的文本数据集，包含多个大类和子类。其中最大3个大类为orgs, people和place，可构造6个跨领域文本分类任务orgs vs people,people vs orgs, orgs vs place, place vs orgs, people vs place和place vs people。

## 行为识别公开数据集

行为识别是典型的时间序列分类任务。为了测试算法在时间序列任务上的性能，收集了3个公开的行为识别数据集：OPPORTUNITY、DASDS和PAMAP2。OPPORTUNITY数据集包含4个用户在智能家居中的多种不同层次的行为。DAADS数据集包含8个人的19种日常行为。PAMAP2数据集包含9个人的18种日常生活行为。所有数据集均包括加速度计、陀螺仪和磁力计三种运动传感器。

## 算法：

收集的数据表征、迁移学习等相关领域的基准算法在持续更新的[Github](https://github.com/jindongwang/transferlearning)上提供了各种算法的实现代码。
